import{_ as r}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as e,f as p}from"./app-VKLC1A-x.js";const t={},s=p('<h1 id="spark" tabindex="-1"><a class="header-anchor" href="#spark" aria-hidden="true">#</a> Spark</h1><h2 id="spark-概述" tabindex="-1"><a class="header-anchor" href="#spark-概述" aria-hidden="true">#</a> Spark 概述</h2><h3 id="spark-简介" tabindex="-1"><a class="header-anchor" href="#spark-简介" aria-hidden="true">#</a> Spark 简介</h3><p>Spark 是一种<em><strong>基于内存</strong></em>的快速、通用、可扩展的<em><strong>大数据计算引擎</strong></em>。基于 MapReduce 的计算引擎通常会将中间结果输出到磁盘上进行存储和容错，而 Spark 则是将<em><strong>中间结果尽量保存在内存中</strong></em>以减少底层存储系统的 I/O，以提高计算速度。同时 <em><strong>Spark 也是一站式解决方案，集批处理、实时流处理、交互式查询、图计算与机器学习于一体的计算引擎</strong></em></p><p>Spark 可以借助 Spark Streaming 组件进行实时的数据计算（但是有一点点的小延迟），这是 MapReduce 不能比的，因为 MapReduce 主要计算的是历史数据</p><p><strong>Spark 的典型应用场景</strong>：</p><p><em><strong>1&gt;</strong></em> 批处理可用于 ETL（抽取、转换、加载）</p><p><em><strong>2&gt;</strong></em> 机器学习可用于自动判断买家评论是好评还是差评</p><p><em><strong>3&gt;</strong></em> 交互式分析可用于查询 Hive 数据仓库</p><p><em><strong>4&gt;</strong></em> 流处理可用于页面点击流分析，推荐系统，舆情分析等实时业务</p><h3 id="spark-的特点" tabindex="-1"><a class="header-anchor" href="#spark-的特点" aria-hidden="true">#</a> Spark 的特点</h3><p><em><strong>1&gt;</strong></em> <strong>轻</strong>：Spark 的核心代码只有 3 万行。同时其支持的 Scala 编程语言非常简洁且具备丰富 的表达力</p><p><em><strong>2&gt;</strong></em> <strong>快</strong>：Spark 不但对小数据集可达到亚秒级的延迟，还可完成对大数据集的迭代机器学习，即席查询、图计算等应用，Spark 版本同样比基于 MapReduce、Hive 和 Pregel 的实现快。同时 Spark 还在内存计算、数据本地性、数据传输和调度都做了优化</p><p><em><strong>3&gt;</strong></em> <strong>灵</strong>：Spark 提供了不同层面的灵活性。Scala 语言 trait 动态混入策略（如可更换的集群调度器、序列化库）。允许扩展新的数据算子、新的数据源、新的 language bindings。Spark 支持内存计算、多迭代批量处理、即席查询、流处理和图计算等多种范式</p><p><em><strong>4&gt;</strong></em> <strong>巧</strong>：Spark 借 Hadoop 之势，与 Hadoop 无缝结合，兼容 Hadoop 生态系统。比如图计算借用 Pregel 和 PowerGraph 的 API 以及 PowerGraph 的点分割思想</p><h2 id="spark-数据结构" tabindex="-1"><a class="header-anchor" href="#spark-数据结构" aria-hidden="true">#</a> Spark 数据结构</h2><h3 id="spark-核心概念-rdd" tabindex="-1"><a class="header-anchor" href="#spark-核心概念-rdd" aria-hidden="true">#</a> Spark 核心概念 RDD</h3><p>RDD（Resilient Distributed Datasets）即弹性分布式数据集，是一个只读的，可分区的分布式数据集</p><p>RDD 的两种创建方式：从 Hadoop 文件系统输入创建；从父 RDD 转换得到新的 RDD</p><p>RDD 还具有血统机制（Lineage），当发生数据丢失时，可快速进行数据恢复，保证了系统的容错率</p><h3 id="rdd-的依赖关系" tabindex="-1"><a class="header-anchor" href="#rdd-的依赖关系" aria-hidden="true">#</a> RDD 的依赖关系</h3><p>血统机制依赖于 RDD 之间的依赖关系，依赖关系分为窄依赖和宽依赖：</p><p><strong>窄依赖</strong>：父的 RDD 和子的 RDD 的 partition（分区）之间的关系是一对一的，或者是多对一的，之间不会有 shuffle 的产生</p><p><strong>宽依赖</strong>：父 RDD 和子 RDD 的 partition 之间的关系是一对多的，之间会有 shuffle 的产生</p><p><strong>RDD 的 Stage 划分</strong>：Spark 任务会根据 RDD 之间的依赖关系形成一个 DAG 有向无环图，DAG 会提交给 DAGScheduler，DAGScheduler 会把 DAG 划分相互依赖的多个 stage，划分 stage 的依据就是 RDD 之间的宽窄依赖</p><h3 id="宽窄依赖的区别" tabindex="-1"><a class="header-anchor" href="#宽窄依赖的区别" aria-hidden="true">#</a> 宽窄依赖的区别</h3><h4 id="算子" tabindex="-1"><a class="header-anchor" href="#算子" aria-hidden="true">#</a> 算子</h4><p>所谓算子可以理解为操作 RDD 的方法或者函数</p><p>算子大致分为两种类型：transform 算子和 action 算子</p><h4 id="容错性" tabindex="-1"><a class="header-anchor" href="#容错性" aria-hidden="true">#</a> 容错性</h4><p>假如某个节点出故障了：</p><p>窄依赖：只要重算和子 RDD 分区对应的父 RDD 分区即可</p><p>宽依赖：极端情况下，所有的父 RDD 分区都要进行重新计算</p><h4 id="传输" tabindex="-1"><a class="header-anchor" href="#传输" aria-hidden="true">#</a> 传输</h4><p>宽依赖对应 shuffle 操作，需要将同一个父 RDD 的分区传入到不同的子 RDD 分区中，中间可能涉及多个节点之间的数据传输</p><p>窄依赖的每个父 RDD 的分区只会传入到一个子 RDD 分区中，通常可以在一个节点内完成转换</p><h2 id="rdd-操作类型" tabindex="-1"><a class="header-anchor" href="#rdd-操作类型" aria-hidden="true">#</a> RDD 操作类型</h2><p>Spark 中的操作可以分为创建操作、控制操作、转换操作和行为操作</p><h2 id="其他数据结构" tabindex="-1"><a class="header-anchor" href="#其他数据结构" aria-hidden="true">#</a> 其他数据结构</h2><p>DataFrame、DataSet</p><h2 id="spark-生态圈" tabindex="-1"><a class="header-anchor" href="#spark-生态圈" aria-hidden="true">#</a> Spark 生态圈</h2><p>Spark 生态圈以 Spark Core 为核心，从 HDFS，HBase 等持久层读取数据，以 Mesos、YARN 和自身携带的 Standalone 为 Cluster Manager 调度 Job 完成 Spark 应用程序的计算，这些应用程序可以来自于不同的组件。如 Spark Shell/Spark Submit 的批处理，Spark Streaming 的实时处理应用，Spark SQL 的即席查询，MLlib 的机器学习，GraphX 的图处理和 SparkR 的数学计算等</p><p><strong>Spark Streaming</strong>：微批处理的流处理引擎，将流数据分片以后用 SparkCore 计算引擎行处理。相对于 Storm，实时性稍差，优势体现在吞吐量上</p><h2 id="spark-sql" tabindex="-1"><a class="header-anchor" href="#spark-sql" aria-hidden="true">#</a> Spark SQL</h2><p>Spark SQL 允许开发人员直接处理 RDD，以及查询存储在 Hive、HBase 上的外部数据</p><ul><li><p><strong>Spark SQL 与 Hive SQL 的主要区别</strong>：</p><p><em><strong>1&gt;</strong></em> Spark SQL 的执行引擎为 Spark Core，Hive 默认执行引擎为 MapReduce</p><p><em><strong>2&gt;</strong></em> Spark SQL 的执行速度是 Hive 的 10-100 倍</p><p><em><strong>3&gt;</strong></em> Spark SQL 不支持 buckets，Hive 支持</p></li><li><p><strong>Spark SQL 与 Hive SQL 的主要联系</strong>：</p><p><em><strong>1&gt;</strong></em> Spark SQL 依赖 Hive 的元数据</p><p><em><strong>2&gt;</strong></em> Spark SQL 兼容绝大部分 Hive 的语法和函数</p><p><em><strong>3&gt;</strong></em> Spark SQL 可以使用 Hive 的自定义函数</p></li></ul>',46),n=[s];function o(d,h){return a(),e("div",null,n)}const S=r(t,[["render",o],["__file","10_Spark.html.vue"]]);export{S as default};
