import{_ as e}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as s,c as t,f as o}from"./app-VKLC1A-x.js";const d={},n=o(`<h1 id="分布式爬虫" tabindex="-1"><a class="header-anchor" href="#分布式爬虫" aria-hidden="true">#</a> 分布式爬虫</h1><h2 id="redis数据库" tabindex="-1"><a class="header-anchor" href="#redis数据库" aria-hidden="true">#</a> Redis数据库</h2><p>Redis是一种支持分布式的<code>nosql</code>数据库，数据保存在内存中，同时支持定时把数据同步到磁盘，即可以将数据持久化。支持的数据结构有：<code>string</code>、<code>list</code>列表[队列和栈]、<code>set</code>[集合]、<code>sorted set</code>[有序集合]、<code>hash</code>(hash表)。参考文档：http://redisdoc.com/index.html</p><ul><li><p><strong>Redis的使用场景</strong></p><p><em><strong>1&gt;</strong></em> 登录会话存储：存储在<code>Redis</code>中，与<code>memcached</code>相比，数据不会丢失</p><p><em><strong>2&gt;</strong></em> 排行版/计数器：比如一些秀场类的项目，经常会有一些前多少名的主播排名。还有一些文章阅读量的技术，或者新浪微博的点赞数等</p><p><em><strong>3&gt;</strong></em> 作为消息队列：比如<code>celery</code>就是使用<code>Redis</code>作为中间人</p><p><em><strong>4&gt;</strong></em> 当前在线人数：还是之前的秀场例子，会显示当前系统有多少在线人数</p><p><em><strong>5&gt;</strong></em> 一些常用的数据缓存：比如我们的<code>BBS</code>论坛，板块不会经常变化的，但是每次访问首页都要从<code>MySQL</code>中获取，可以在<code>Redis</code>中缓存起来，不用每次请求数据库</p><p><em><strong>6&gt;</strong></em> 把前200篇文章缓存或者评论缓存：一般用户浏览网站，只会浏览前面一部分文章或者评论，那么可以把前面200篇文章和对应的评论缓存起来。用户访问超过的，就访问数据库，并且以后文章超过200篇，则把之前的文章删除</p><p><em><strong>7&gt;</strong></em> 好友关系：微博的好友关系使用<code>Redis</code>实现</p><p><em><strong>8&gt;</strong></em> 发布和订阅功能：可以用来做聊天软件</p></li><li><p><strong>Redis和memcached的比较</strong></p><table><thead><tr><th></th><th><strong>memcached</strong></th><th><strong>Redis</strong></th></tr></thead><tbody><tr><td><strong>类型</strong></td><td>纯内存数据库</td><td>内存磁盘同步数据库</td></tr><tr><td><strong>数据类型</strong></td><td>在定义value时就要固定数据类型</td><td>不需要</td></tr><tr><td><strong>虚拟内存</strong></td><td>不支持</td><td>支持</td></tr><tr><td><strong>过期策略</strong></td><td>支持</td><td>支持</td></tr><tr><td><strong>存储数据安全</strong></td><td>不支持</td><td>可以将数据同步到dump.db中</td></tr><tr><td><strong>灾难恢复</strong></td><td>不支持</td><td>可以将磁盘中的数据恢复到内存中</td></tr><tr><td><strong>分布式</strong></td><td>支持</td><td>主从同步</td></tr><tr><td><strong>订阅与发布</strong></td><td>不支持</td><td>支持</td></tr></tbody></table></li><li><p><strong>Redis的安装</strong></p><ul><li><p><em><strong>Ubuntu系统</strong></em></p><p><em><strong>1&gt;</strong></em> 安装：<code>sudo apt-get install redis-server</code></p><p><em><strong>2&gt;</strong></em> 卸载：<code>sudo apt-get purge --auto-remove redis-server</code></p><p><em><strong>3&gt;</strong></em> 启动：<code>sudo service redis-server start</code></p><p><em><strong>4&gt;</strong></em> 查看是否启动：<code>ps aux|grep redis</code></p><p><em><strong>5&gt;</strong></em> 停止：<code>sudo service redis-server stop</code></p></li><li><p><em><strong>Windows系统</strong></em></p><p><em><strong>1&gt;</strong></em> 下载：Redis官方是不支持Windows操作系统的，但是微软的开源部门将Redis移植到了Windows上，因此下载地址不是在Redis官网上，而是在github上：https://github.com/MicrosoftArchive/redis/releases</p><p><em><strong>2&gt;</strong></em> 安装：一直点击下一步进行安装就可以了</p><p><em><strong>3&gt;</strong></em> 运行：进入到<code>Redis</code>安装所在的路径然后执行<code>redis-server.exe redis.windows.conf</code>就可以运行了</p><p><em><strong>4&gt;</strong></em> 连接：<code>Redis</code>和<code>MySQL</code>以及<code>mongo</code>是一样的，都提供了一个客户端进行连接，输入命令<code>redis-cli</code>（前提是Redis安装路径已经加入到环境变量中了）就可以连接到<code>Redis</code>服务器了</p></li><li><p><em><strong>Redis可视化管理工具</strong></em></p><p>Redis Desktop Manager，下载地址：https://www.cnblogs.com/mike-mei/p/15271502.html</p></li></ul></li><li><p><strong>其他机器访问本机Redis服务器</strong></p><p>想要让其他机器访问本机的Redis服务器，需要修改<code>redis.conf</code>的配置文件，将<code>bind</code>改成<code>bind [本机的ip地址或者0.0.0.0]</code>，其他机器才能访问</p><p><em><strong>注</strong></em>：<code>bind</code>绑定的是本机网卡的ip地址，而不是想让其他机器连接的ip地址。如果有多块网卡，那么可以绑定多个网卡的ip地址；如果绑定的是<code>0.0.0.0</code>，那么意味着其他机器可以通过本机所有的ip地址进行访问</p></li></ul><h2 id="scrapy-redis分布式爬虫组件" tabindex="-1"><a class="header-anchor" href="#scrapy-redis分布式爬虫组件" aria-hidden="true">#</a> Scrapy-Redis分布式爬虫组件</h2><p>借助Scrapy-Redis组件，利用Redis分布式的功能，集成到Scrapy框架中，实现分布式爬虫</p><ul><li><p><strong>分布式爬虫优点</strong></p><p><em><strong>1&gt;</strong></em> 可以充分利用多台机器的带宽</p><p><em><strong>2&gt;</strong></em> 可以充分利用多台机器的ip地址</p><p><em><strong>3&gt;</strong></em> 多台机器同时爬取，效率更高</p></li><li><p><strong>需要解决的问题</strong></p><p><em><strong>1&gt;</strong></em> 如何保证不同机器不会重复爬取相同的页面</p><p><em><strong>2&gt;</strong></em> 在爬取完成后，如何让数据保存在同一个地方</p></li><li><p><strong>分布式爬虫部署</strong></p><ul><li><p><em><strong>代码修改</strong></em></p><p>将Scrapy项目变成Scrapy-Redis项目需要修改以下三点：</p><p><em><strong>1&gt;</strong></em> 将爬虫的类从<code>scrapy.Spider</code>变成<code>scrapy_redis.spiders.RedisSpider</code>；或者是从<code>scrapy.CrawlSpider</code>变成<code>scrapy_redis.spiders.RedisCrawlSpider</code></p><p><em><strong>2&gt;</strong></em> 将爬虫中的<code>start_urls</code>删掉，并增加一个<code>redis_key=&quot;xxx&quot;</code>。这个<code>redis_key</code>是为了以后在<code>redis</code>中控制爬虫启动的第一个<code>url</code>，就是在<code>redis</code>中通过这个发送出去的</p><p><em><strong>3&gt;</strong></em> 在配置文件<code>settings.py</code>中增加如下配置：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Scrapy-Redis相关配置</span>
<span class="token comment"># 确保request存储到redis中</span>
SCHEDULER <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span>
<span class="token comment"># 确保所有爬虫共享相同的去重指纹</span>
DUPEFILTER_CLASS <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span>
<span class="token comment"># 设置redis为item pipeline</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&#39;scrapy_redis.pipelines.RedisPipeline&#39;</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
<span class="token comment"># 在redis中保持scrapy-redis用到的队列，不会清理redis中的队列，从而可以实现暂停和恢复的功能</span>
SCHEDULER_PERSIST <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token comment"># 设置连接redis的信息</span>
REDIS_HOST <span class="token operator">=</span> <span class="token string">&#39;127.0.0.1&#39;</span>
REDIS_PORT <span class="token operator">=</span> <span class="token number">6379</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><em><strong>运行爬虫</strong></em></p><p><em><strong>1&gt;</strong></em> 在爬虫服务器上：进入爬虫文件所在的路径，运行命令：<code>scrapy runspider [爬虫名字]</code></p><p><em><strong>2&gt;</strong></em> 在<code>Redis</code>服务器上：推入一个开始的<code>url</code>链接：<code>redis-cli&gt; lpush [redis_key] start_url</code>开始爬取</p></li></ul></li></ul>`,7),r=[n];function i(p,c){return s(),t("div",null,r)}const l=e(d,[["render",i],["__file","07_分布式爬虫.html.vue"]]);export{l as default};
